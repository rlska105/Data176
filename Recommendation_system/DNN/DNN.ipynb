{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN\n",
    "\n",
    "- recommender system에서 DNN은 MF의 몇가지 문제를 해결합니다.<br>\n",
    "    1.cold start problem due to the fact that it had no feature vector.<br>\n",
    "    2.often tends to recommend just popular items to everyone which does not always reflect the specific user interests<br>\n",
    "    3.often not enough to capture and represent the complex relations in the user and items.<br>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algotithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NCF (Neural Collaborative Filtering)\n",
    "- 개요\n",
    "    - user latent factor와 item latent factor간의 상관관계를 표현하는데 MLP를 사용한다는 관점에서 다음과 같은 구조로 표현할 수 있음. user embedding과 item embedding을 latent factor로 보고 그 두 개의 vector를 뉴럴넷에 넣어서 훈련시키는 것을 NCF라고 함.<br><br>\n",
    "- Process\n",
    "    - NCF takes in two sparse vectors, one representing the user and the other represents items. The item vector has 1 at an index means the user has interacted with the item corresponding to the index. Basically both items and users are one-hot encoded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NeuMF\n",
    "- GMF(General Matrix Factorization) : MF의 일반화 버전으로 MF에서는 단순 dot-product로만 output을 예측했다면 GMF에서는 element마다의 weight를 학습함. p와 q가 embedding인데 두 embedding을 element-wise로 곱한 다음에 weight를 곱함. 그리고 non-linear activation function을 사용해서 모델이 user-item interaction을 더 풍부하게 표현할 수 있도록 함. h가 uniform vector이고 a가 1이면 그게 바로 MF<br><br>\n",
    "- Schema : GMF와 MLP가 각자 다른 특성을 가지고 있는데 이걸 합쳐버리면 더 복잡한 user-item interaction도 표현할 수 있지 않을까?라는 질문에서 시작됨. an idea of a NeuMF as a Fusion of general Matrix factorization GMF and Multiperceptron layer MLP with the name NeuMF. The general idea behind the fusion is that the GMF better generates the linear dependencies and the MLP better models the non-linear dependencies of in the user-item interactions. Here the MLP’s item and user vectors and GMF layer’s user and item vectors are separately trained, so, that they can reach individual optimality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN\n",
    "- Schema : A Convolutional Neural Network can be used. We can split the watch history sequence into training windows and shift the 1 Dimensional training window over the interaction sequence of a particular user to get the embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax layer\n",
    "- add"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function\n",
    "add"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective function\n",
    "- Pointwise Loss\n",
    "    - follows a regression framework by minimizing the squared loss between predicted score y_(u,i) and target value y(u,i). In order to account for negative feedback either all unobserved entries are considered as negative examples or some unobserved entries are sampled to be negative instances.<br>\n",
    "- Pairwise Loss or Ranking Loss\n",
    "    - aims to rank observed entries higher than the unobserved ones. It achieves this by maximizing the margin between observed entries and unobserved entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
