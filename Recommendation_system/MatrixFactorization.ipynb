{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Filtering model (CF)\n",
    "- 개요 : CF는 유저와 아이템에 대한 matrix를 만든 뒤, 유저 기반 혹은 아이템 기반으로 유사한 객체를 찾은 뒤 빈공간을 추론하는 알고리즘입니다. 크게 Memory-based(also known as Neighborhood-based collaborative filtering algorithms)와 Model-based가 있습니다.<br><br>\n",
    "\n",
    "- 장점 : 고객 기반의 데이터를 사용하기 때문에 연관 있는 컨텐츠를 추천해 좋은 고객 경험을 줄 수 있습니다.<br><br>\n",
    "\n",
    "- 단점 : 모든 고객이 rating을 주지 않기 때문에 martix에서 생기는 sparsity문제가 발생 할 수 있고, 초기에 데이터를 많이 확보 할 수 없는 cold start문제가 생길 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Memory-based\n",
    "- 이 방법은 사용자의 과거 interactions 메모리를 사용하여 유저의 유사성을 계산합니다. 이것을 user-based approach이라고 합니다. 반대도 마찬가지로 아이템의 유사성을 찾는 것을 item-based approach라고 합니다.\n",
    "\n",
    "- Process : 각각의 유저와 아이템 유사도를 계산해 거리(거리를 구할 땐 kNN과 맨해튼 거리를 사용할 수 있습니다.)와 상관관계를 구합니다. 계산된 유사도를 가지고 타켓 유저를 예측하고 top N개의 추천을 합니다.  \n",
    "    - Correlation : 유사도를 찾기 위해서는 유저 또는 아이템의 상관관계를 파악해야 하는데 여기에는 몇가지 방법이 있습니다. 가장 흔하게 쓰는 방법으로는 피어슨 상관계수가 있고, 유저간에 평균 제곱차를 구하는 Mean squared diffrence (MSD)이 있습니다. 이 방법은 피어슨 상관계수와 유사합니다.<br><br> \n",
    "- 장점 : Memory-based의 장점은 예측의 정확도가 Model-based보다 높으며 알고리즘 구조가 간단합니다.\n",
    "    \n",
    "- 단점 : Memory-based의 가장 큰 단점은 in-memory에 있는 모든 데이터를 불러와야 한다는 것입니다. 그렇기 때문에 많은 사용자가 이용하고 있는 시스템에서는 matrix가 기하급수적으로 커지는 현상이 나타날 수 있습니다.<br>\n",
    "- Memory-based와 Model-based의 가장 큰 차이는 Memory-based는 GD(Gradient descent)를 비롯한 어떠한 최적화 알고리즘을 사용하지 않습니다. 하지만 유저의 상관관계를 찾기 위해 코사인 유사도와 피어슨의 상관관계를 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model-based\n",
    "- 정의 : 이 방법은 다양한 모델을 사용함으로써 유저에게 추천을 하는 방법입니다. neural networks, bayesian networks, clustering models, and latent factor models such as Singular Value Decomposition (SVD)등의 알고리즘이 있고, 최신 알고리즘들이 계속해서 업데이트 되고 있습니다. \n",
    "\n",
    "- 장점 : 컴퓨팅 자원 소모가 매우큰 Memory-based에 반해 Model-based은 다양한 제안으로 이 문제를 해결할 수 있습니다. clustering, classification, latent model, Markov decision process (MDP), and matrix factorization과 같은 방법이 사용될 수 있습니다. \n",
    "\n",
    "\n",
    "### Matrix factorization\n",
    "- 정의 : 우선 MF 모델은 본질적으로는 행렬을 분해하고 분해한 행렬을 변수로써 학습하는 것입니다. MF의 목적은 아직 평가를 내리지 않은 user-item의 빈 공간을 Model-based Learning으로 채워넣는 것을 의미합니다. 과거에는 data의 양이 크지 않아 missing value를 처리할 때 imputation에 많은 노력을 쏟았지만 현재는 데이터의 volume이 커지면서 차원을 줄이는 것에 큰 의미를 두고 있습니다.<br><br>\n",
    "\n",
    "- Model : MF model은 user와 item을 latent factor space에 넣기 위해 매핑합니다. item i는 vector q와 연관이 있고, user u는 vector p와 연관이 있습니다. 모델이 수행해야 할 가장 큰 숙제는 user와 item의 매핑을 계산하는 것 입니다. 모델의 종류로는 SVD(Singular Value Decomposition)와 NMF(Non-negative matrix factorization)등이 있고 이것은 CF와 큰 연관이 있습니다.<br><br>\n",
    "\n",
    "- Types of Matrix factorization\n",
    "    - LU decomposition LU 분해는 matrix를 L과 U로 분해하여 L은 아랫쪽 삼각형 matrix를 형성하고 U는 윗쪽 삼각형 matrix를 형성합니다. 보통 선형 회귀의 계수를 찾을 때 사용합니다.\n",
    "    - QR matrix decomposition QR분해는 Q와 R로 분해해 Q는 정사각형 matrix가 되고 R은 윗쪽 삼각혁이 되어 eigen system analysis를 위해 사용합니다.\n",
    "    - Cholesky Decomposition- 이것은 머신러닝에서 분해할때 가장 많이 사용되는 방법입니다. 선형 회귀를 위한 선형 최소 제곱을 계산하는데 사용할 수 있습니다.<br><br>\n",
    "\n",
    "- Process data : 데이터를 처리하기 위해서 원본 데이터에서 3000 x 5000 sub-matrix데이터를 추출했고 약 98%이 0였기 때문에 차원 축소를 진행하여 502 x 1528의 matrix를 얻었습니다.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
